{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra\n",
    "Linear algerba is a branch of mathematics essential for understanding and working with machine learning algorithms. Some key concepts from linear algebra useful for deep learning concepts include scalars, vectors, matrices, and tensors, multiplying matrices, identity and inverse matrices, linear dependence, span, norms, eigendecomposition, singular value decomposition, etc.\n",
    "\n",
    "In this notebook, I will code some of the more applied linear algebra techniques such as various types of norms, eigendeomposition, singular value decomposition, and principal component analysis. Many of these techniques have a prewritten numpy or other library function to compute them, but for learning purposes we will recreate them using some of the simpler numpy functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norms\n",
    "Norms are denoted as L<sup>p</sup> and include some of the following:\n",
    "* Euclidean (L<sup>2</sup>)\n",
    "* L<sup>1</sup>\n",
    "* Max norm\n",
    "* Frobenius norm\n",
    "\n",
    "#### Euclidean Norm and other L<sup>p</sup> norms\n",
    "Euclidean norm is the distance between the origin and point identified as x, denoted as L<sup>2</sup>. The L<sup>2</sup> norm is very common and often referred to as ||x||. It is also common to measure the size of a vector using the squared L<sup>2</sup> norm, which is also just x<sup>T</sup>x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm has size of 5.543464620614079\n"
     ]
    }
   ],
   "source": [
    "x = np.array([2.5,-4.8,1.2])\n",
    "p = 2\n",
    "norm = sum(abs(x)**p)**(1/p)\n",
    "print(f\"L{p} norm has size of {norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functionalize the Norm calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.543464620614079\n"
     ]
    }
   ],
   "source": [
    "def norm(x,p=2):\n",
    "    assert p >=1, \"p must be greater than or equal to 1\"\n",
    "    \n",
    "    return np.sum(abs(x)**p)**(1/p)\n",
    "\n",
    "print(norm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three ways to calculate squared L<sup>2</sup> norm shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.73\n",
      "30.73\n",
      "30.73\n"
     ]
    }
   ],
   "source": [
    "print(norm(x)**2)\n",
    "print(x.T.dot(x))\n",
    "print(sum(x.T*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Norm\n",
    "Simplifies to the absolute value of the element with the largest magnitude of the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Max norm of the vector [ 2.5 -4.8  1.2] is 4.8\n"
     ]
    }
   ],
   "source": [
    "x = np.array([2.5,-4.8,1.2])\n",
    "\n",
    "print(f\"The Max norm of the vector {x} is {max(abs(x))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frobenius Norm\n",
    "Most common way to measure the size of a matrix in the context of deep learning is with the Frobenius norm, which is anagolous to the L<sup>2</sup> norm of a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.58792474949678"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[6.7,-8.1],[-2.3,4.3]])\n",
    "sum(sum(A**p))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.58792474949678"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigendecomposition\n",
    "Decomposing (breaking down) a matrix into a set of eigenvectors and eigenvalues.\n",
    "* <b>Eigenvector</b> of a square matrix A is a nonzero vector v such that multiplication by A gives us back a scaled version of v. (Av = cv where c is that scalar)\n",
    "* <b>Eigenvalue</b> actually ends up being that scalar (or c) corresponding to this eigenvector. It may also be important to note that left eigenvectors are possible so that v<sup>T</sup>A = cv<sup>T</sup>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors (column wise):\n",
      "[[ 0.58428153  0.73595785  0.40824829]\n",
      " [ 0.80407569 -0.38198836 -0.81649658]\n",
      " [ 0.10989708 -0.55897311  0.40824829]]\n",
      "Eigenvalues:\n",
      "[ 4.31662479e+00 -2.31662479e+00  1.93041509e-17]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3],[3,2,1],[1,0,-1]])\n",
    "eigen_value,eigen_vector = np.linalg.eig(A)\n",
    "\n",
    "print(\"Eigenvectors (column wise):\")\n",
    "print(eigen_vector)\n",
    "\n",
    "print(\"Eigenvalues:\")\n",
    "print(eigen_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix A multiplied by the eigenvector should equal the eigenvalue * eigenvector\n",
      "A*v = [-1.7049382   0.88492371  1.29493096]\n",
      "c*v = [-1.7049382   0.88492371  1.29493096]\n"
     ]
    }
   ],
   "source": [
    "print(\"The matrix A multiplied by the eigenvector should equal the eigenvalue * eigenvector\")\n",
    "i = 1\n",
    "print(f\"A*v = {A.dot(eigen_vector[:,i])}\")\n",
    "print(f\"c*v = {eigen_value[i]*eigen_vector[:,i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the full <b>eigendecomposition</b> by concatenating all eigenvectors of a matrix column-wise and then putting all the corresponding eigenvalues in a vector.\n",
    "\n",
    "If v is an eigenvector of A, then that means so is any rescaled vector cv, but cv still has the same eigenvalue. For this reason, usually you would only look for the unit eigenvectors (i.e. a vector with a unit norm ||x||<sub>2</sub> = 1). \n",
    "\n",
    "To make a unit eigenvector/vector you divide each element of vector v by the L<sup>2</sup> norm. Seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of vector v is: 5.543464620614079\n",
      "So now we can divide vector v by the Norm [ 0.4509815  -0.86588448  0.21647112]\n",
      "Now we can check that this is in fact a unit vector by taking the norm of this new vector: 1.0\n",
      "We know this is a unit vector since it is equivalent to 1\n"
     ]
    }
   ],
   "source": [
    "v = np.array([2.5,-4.8,1.2])\n",
    "print(f\"Norm of vector v is: {norm(v)}\")\n",
    "print(f\"So now we can divide vector v by the Norm {v/norm(v)}\")\n",
    "print(f\"Now we can check that this is in fact a unit vector by taking the norm of this new vector: {norm(v/norm(v))}\")\n",
    "print(f\"We know this is a unit vector since it is equivalent to 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigendecomposition can be expressed with the following formula:\n",
    "A = V diag(c) V<sup>-1</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  2.00000000e+00,  3.00000000e+00],\n",
       "       [ 3.00000000e+00,  2.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.07568059e-16, -1.00000000e+00]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_vector.dot((np.diag(eigen_value))).dot(np.linalg.inv(eigen_vector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
